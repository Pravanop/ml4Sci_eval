{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 3 Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1LLaVpEX6rApORCXcHwhHFk-myojuDoOW",
      "authorship_tag": "ABX9TyOXS8+LGJEbiPqlRzX/AXMP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pravanop/ml4Sci_eval/blob/main/Task_3_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We0kJVKuSaNB",
        "outputId": "bf347cdc-12f8-4216-a5c9-599edb9f3815"
      },
      "source": [
        "!pip install pyarrow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DydRklifbUSu"
      },
      "source": [
        "!cd '/content/drive/MyDrive/GSOC/Application/ML4Sci/Task 3/dataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhq1XPA5PhWB",
        "outputId": "f7d04e4b-c352-4f22-e7fc-b284cf3764fa"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/GSOC/Application/ML4Sci/Task 3/download (1).zip' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/GSOC/Application/ML4Sci/Task 3/download (1).zip\n",
            " extracting: E2E_Regression.parquet.1  \n",
            " extracting: E2E_Regression.parquet.10  \n",
            " extracting: E2E_Regression.parquet.11  \n",
            " extracting: E2E_Regression.parquet.12  \n",
            " extracting: E2E_Regression.parquet.14  \n",
            " extracting: E2E_Regression.parquet.15  \n",
            " extracting: E2E_Regression.parquet.16  \n",
            " extracting: E2E_Regression.parquet.17  \n",
            " extracting: E2E_Regression.parquet.18  \n",
            " extracting: E2E_Regression.parquet.19  \n",
            " extracting: E2E_Regression.parquet.2  \n",
            " extracting: E2E_Regression.parquet.3  \n",
            " extracting: E2E_Regression.parquet.4  \n",
            " extracting: E2E_Regression.parquet.5  \n",
            " extracting: E2E_Regression.parquet.6  \n",
            " extracting: E2E_Regression.parquet.7  \n",
            " extracting: E2E_Regression.parquet.8  \n",
            " extracting: E2E_Regression.parquet.9  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX8adtQ0T7zD"
      },
      "source": [
        "import pyarrow.parquet as pq\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvpfPcl8YQDS"
      },
      "source": [
        "class jetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, path):\n",
        "      self.table = pq.ParquetFile(path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.table.num_row_groups\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.table.read_row_group(idx)\n",
        "        jet = row.column('X_jet').to_numpy()\n",
        "        label = row.column('y').to_numpy()\n",
        "        three_array = []\n",
        "        for j,m in enumerate(jet[0]):\n",
        "          arr = []\n",
        "          for i,k in enumerate(jet[0][j]):\n",
        "            if i == 0:\n",
        "              arr = k\n",
        "              arr = arr.reshape(arr.shape[0],1)\n",
        "            else:\n",
        "              k = k.reshape(k.shape[0],1)\n",
        "              arr = np.concatenate((arr,k),axis=0)\n",
        "          if j == 0 :\n",
        "            three_array = arr\n",
        "          else:\n",
        "            three_array = np.concatenate((three_array,arr),axis=0)\n",
        "        \n",
        "        three_array_reshaped = three_array.reshape(125,125,4)\n",
        "        am = row.column('am').to_numpy()[0]\n",
        "        am_arr = np.ones((125,125))*am\n",
        "        image = np.dstack((three_array_reshaped[:,:,0],three_array_reshaped[:,:,-1],am_arr)) #using pt,ecal and am as features for the image\n",
        "        x = torch.tensor(image)\n",
        "        label = label[0]\n",
        "        \n",
        "        sample = (x, label)\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwzab-bRaabg"
      },
      "source": [
        "#had to manually extract due to discrepancy in colab\n",
        "data1 = jetDataset('/content/E2E_Regression.parquet.1')\n",
        "data2 = jetDataset('/content/E2E_Regression.parquet.2')\n",
        "data3 = jetDataset('/content/E2E_Regression.parquet.3')\n",
        "data4 = jetDataset('/content/E2E_Regression.parquet.4')\n",
        "data5 = jetDataset('/content/E2E_Regression.parquet.5')\n",
        "data6 = jetDataset('/content/E2E_Regression.parquet.6')\n",
        "data7 = jetDataset('/content/E2E_Regression.parquet.7')\n",
        "data8 = jetDataset('/content/E2E_Regression.parquet.8')\n",
        "data9 = jetDataset('/content/E2E_Regression.parquet.9')\n",
        "data10 = jetDataset('/content/E2E_Regression.parquet.10')\n",
        "data11 = jetDataset('/content/E2E_Regression.parquet.11')\n",
        "data12 = jetDataset('/content/E2E_Regression.parquet.12')\n",
        "data14 = jetDataset('/content/E2E_Regression.parquet.14')\n",
        "data15 = jetDataset('/content/E2E_Regression.parquet.15')\n",
        "data16 = jetDataset('/content/E2E_Regression.parquet.16')\n",
        "data17 = jetDataset('/content/E2E_Regression.parquet.17')\n",
        "data18 = jetDataset('/content/E2E_Regression.parquet.18')\n",
        "data19 = jetDataset('/content/E2E_Regression.parquet.19')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "341kVbgQcrz1",
        "outputId": "30040d3d-dc0a-43a6-af87-ce940a6eeb89"
      },
      "source": [
        "sample = data17[0][1]\n",
        "type(sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz5CGPWmhJrM"
      },
      "source": [
        "all_datasets = [data1,data2,data3,data4,data5,data6,data7,data8,data9,data10,data11,data12,data14,data15,data16,data17,data18,data19]\n",
        "final_dataset = torch.utils.data.ConcatDataset(all_datasets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbn2T6RZjsDH"
      },
      "source": [
        "train_size = int(0.8 * len(final_dataset))\n",
        "test_size = len(final_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(final_dataset, [train_size, test_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-S7wNMHjwot"
      },
      "source": [
        "datasets = {'train':train_dataset,'val':test_dataset}\n",
        "dataloaders = {x: DataLoader(datasets[x], batch_size= 1024, shuffle=True, num_workers=0) for x in ['train','val']}\n",
        "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH1BX83Hkbba",
        "outputId": "11cfcb46-a283-4e45-d308-ee577020d827"
      },
      "source": [
        "print(dataset_sizes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': 92284, 'val': 23071}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sIHV1Mrj6az"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xyx8diDht5p"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvIDfU2djrDK"
      },
      "source": [
        "res_mod = models.resnet34(pretrained=True)\n",
        "num_ftrs = res_mod.fc.in_features\n",
        "res_mod.fc = nn.Linear(num_ftrs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh2ldhJLkGY_"
      },
      "source": [
        "res_mod = res_mod.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(res_mod.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuk7RaAOkQlh"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            current_loss = 0.0\n",
        "            current_corrects = 0\n",
        "\n",
        "            print('Iterating through data...')\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                torch.cuda.empty_cache()\n",
        "                inputs = inputs.permute(0, 3, 1, 2)\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs.float())\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels.long())\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                current_loss += loss.item() * inputs.size(0)\n",
        "                current_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = current_loss / dataset_sizes[phase]\n",
        "            epoch_acc = current_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # Make a copy of the model if the accuracy on the validation set has improved\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_since = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_since // 60, time_since % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "zYgTzK_2kk2X",
        "outputId": "8d974fc8-9525-40c6-c265-f7d849282252"
      },
      "source": [
        "base_model = train_model(res_mod, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/0\n",
            "----------\n",
            "Iterating through data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-fdfb113db810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-fefec65b66e8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 184.00 MiB (GPU 0; 14.76 GiB total capacity; 13.66 GiB already allocated; 21.75 MiB free; 13.70 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKGiB1dXknDu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}